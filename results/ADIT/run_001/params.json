{
  "model_name": "gpt2-xl",
  "device": "cpu",
  "layers": [
    13,
    14,
    15,
    16,
    17
  ],
  "rewrite_module_tmp": "transformer.h.{}.mlp.c_proj",
  "lf_rank": 8,
  "le_rank": 16,
  "alpha": 16.0,
  "v_num_grad_steps": 20,
  "lr_lf": 0.0005,
  "lr_le": 0.0005,
  "batch_size_forget": 3,
  "batch_size_edit": 1,
  "edit_per_forget": 5,
  "lambda_loc": 1.0,
  "lambda_kl": 1.0,
  "lambda_spec": 0.5,
  "lambda_orth": 0.05,
  "use_direct_supervision": true,
  "prediction_weight": 1.0,
  "representation_weight": 0.5,
  "invariance_weight": 0.2,
  "specificity_weight": 0.3,
  "ctx_dim": 1600,
  "context_generation": "embedding_mean",
  "learned_context_dim": 512,
  "use_position_context": true,
  "fact_token": "subject_first",
  "use_vector_guidance": true,
  "vector_guidance_weight": 0.3,
  "vector_alignment_weight": 0.1,
  "clamp_norm_factor": 1.0
}